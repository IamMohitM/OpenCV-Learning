{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have a lot of small pieces of images, where we need to assemble them correctly to form a big real image. How do you arrange lots of scrambled image pieces into a big single image? How can you stitch a lot of natural images to a single iamge?\n",
    "\n",
    "We are looking got specific patterns or specific features which are unique, which can be easily tracked, features which can be easily compared. \n",
    "\n",
    "Recognizing features in an image is inherent and easy to humans.\n",
    "\n",
    "Given an image of a building and 2 patches from the image. Consider the first patch is of a flat surface and the second patch is a corner of a roof on the building. The flat surface is spread in many areas, so it's difficult to find the exact location of the first patch. But the corners of a building are easily found out because at corners wherever you mobe htis patch it will look different. So the second patch can be considered a good feature.\n",
    "\n",
    "So corners are good features. How do we find them? Look for the regions in an image which maximum variation when moved(by a small amount) in all region around it. Finding these image features is called **Feature Detection**.\n",
    "\n",
    "Once the features are found, we need to find the same in the other inmages. We take a region around the feature, and search for the same area in other images. We take a region around the feature, we explain it in our own words, like “upper part is blue sky, lower part is building region, on that building there are some glasses etc” and you search for the same area in other images. Basically, you are describing the feature. Similar way, computer also should describe the region around the feature so that it can find it in other images. So called description is called Feature Description. Once you have the features and its description, you can find same features in all images, align them or stitch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
